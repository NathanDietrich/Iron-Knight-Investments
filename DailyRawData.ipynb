{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1VsduyUsYkOZHv6iFhfh3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NathanDietrich/Iron-Knight-Investments/blob/main/DailyRawData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqPPsRxwmvDV",
        "outputId": "574b844b-b299-4aff-b565-0f822916ca14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Polygon.io API key: ··········\n",
            "Polygon data doesn’t have today's partial bar yet. No row created.\n",
            "No row returned.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import time\n",
        "from textblob import TextBlob\n",
        "\n",
        "def fetch_recent_stock_data_polygon(ticker, lookback_days, api_key):\n",
        "    \"\"\"\n",
        "    Fetches ~lookback_days of daily stock data from Polygon.io, including\n",
        "    (possibly partial) data for today if the market is open.\n",
        "    \"\"\"\n",
        "    end_date_dt = datetime.date.today()  # \"Today\"\n",
        "    start_date_dt = end_date_dt - datetime.timedelta(days=lookback_days)\n",
        "\n",
        "    start_date = start_date_dt.strftime(\"%Y-%m-%d\")\n",
        "    end_date   = end_date_dt.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    url = (\n",
        "        f\"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/day/\"\n",
        "        f\"{start_date}/{end_date}?apiKey={api_key}\"\n",
        "    )\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error fetching stock data: {response.text}\")\n",
        "        return None\n",
        "\n",
        "    data = response.json()\n",
        "    if \"results\" not in data:\n",
        "        print(\"No results found in Polygon data.\")\n",
        "        return None\n",
        "\n",
        "    df = pd.DataFrame(data[\"results\"])\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"t\"], unit=\"ms\").dt.date\n",
        "    df.rename(columns={\"o\": \"Open\", \"h\": \"High\", \"l\": \"Low\", \"c\": \"Close\", \"v\": \"Volume\"}, inplace=True)\n",
        "    df = df[[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "    df.sort_values(\"Date\", inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def fetch_recent_sentiment_polygon(ticker, lookback_days, api_key, limit=1000):\n",
        "    \"\"\"\n",
        "    Fetches news from Polygon.io for ~lookback_days, computing daily average\n",
        "    sentiment polarity & subjectivity. This includes today's partial news if available.\n",
        "    \"\"\"\n",
        "    end_date_dt = datetime.date.today()\n",
        "    start_date_dt = end_date_dt - datetime.timedelta(days=lookback_days)\n",
        "    start_date = start_date_dt.strftime(\"%Y-%m-%d\")\n",
        "    end_date   = end_date_dt.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    url = \"https://api.polygon.io/v2/reference/news\"\n",
        "    all_results = []\n",
        "    current_start_date = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    final_end_date = datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "\n",
        "    while current_start_date < final_end_date:\n",
        "        chunk_end_date = current_start_date + datetime.timedelta(days=30)\n",
        "        if chunk_end_date > final_end_date:\n",
        "            chunk_end_date = final_end_date\n",
        "\n",
        "        chunk_start_str = current_start_date.strftime(\"%Y-%m-%d\")\n",
        "        chunk_end_str = chunk_end_date.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        params = {\n",
        "            \"ticker\": ticker,\n",
        "            \"published_utc.gte\": chunk_start_str,\n",
        "            \"published_utc.lte\": chunk_end_str,\n",
        "            \"apiKey\": api_key,\n",
        "            \"limit\": limit\n",
        "        }\n",
        "\n",
        "        while True:\n",
        "            response = requests.get(url, params=params)\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                results = data.get(\"results\", [])\n",
        "                all_results.extend(results)\n",
        "\n",
        "                next_cursor = data.get(\"next_cursor\")\n",
        "                if not next_cursor:\n",
        "                    break\n",
        "                params[\"cursor\"] = next_cursor\n",
        "            else:\n",
        "                print(f\"⚠️ Error fetching sentiment data: {response.status_code}, {response.text}\")\n",
        "                break\n",
        "\n",
        "        current_start_date = chunk_end_date\n",
        "        time.sleep(1.5)  # small delay\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    if not all_results:\n",
        "        return pd.DataFrame()\n",
        "    news_df = pd.DataFrame(all_results)\n",
        "\n",
        "    # Compute sentiment using TextBlob\n",
        "    sentiments = []\n",
        "    for _, row in news_df.iterrows():\n",
        "        title = row.get(\"title\", \"\")\n",
        "        description = row.get(\"description\", \"\")\n",
        "        full_text = f\"{title} {description}\"\n",
        "        sentiment = TextBlob(full_text).sentiment\n",
        "        sentiments.append({\n",
        "            \"published_utc\": row.get(\"published_utc\", \"\"),\n",
        "            \"sentiment_polarity\": sentiment.polarity,\n",
        "            \"sentiment_subjectivity\": sentiment.subjectivity\n",
        "        })\n",
        "    sentiment_df = pd.DataFrame(sentiments)\n",
        "\n",
        "    # Group by date\n",
        "    sentiment_df[\"published_date\"] = pd.to_datetime(sentiment_df[\"published_utc\"], errors=\"coerce\").dt.date\n",
        "    daily_sentiment = sentiment_df.groupby(\"published_date\").agg({\n",
        "        \"sentiment_polarity\": \"mean\",\n",
        "        \"sentiment_subjectivity\": \"mean\"\n",
        "    }).reset_index()\n",
        "    daily_sentiment.rename(columns={\"published_date\": \"Date\"}, inplace=True)\n",
        "\n",
        "    return daily_sentiment\n",
        "\n",
        "\n",
        "def assemble_today_prediction_row(ticker, api_key, lookback_days=30):\n",
        "    \"\"\"\n",
        "    Fetches enough data (stock & sentiment) to produce a single row of features\n",
        "    for 'today's predicted close.'\n",
        "      - 'prev_' columns are from YESTERDAY's EOD\n",
        "      - 'Open_current' is from TODAY's partial bar (the open)\n",
        "\n",
        "    Returns a DataFrame with exactly 1 row:\n",
        "      [prev_Open, prev_High, ..., prev_sentiment_subjectivity, Open_current]\n",
        "    If not enough data is fetched (e.g. no trading yet), returns None.\n",
        "    \"\"\"\n",
        "    # 1) Fetch historical daily data (includes yesterday + partial for today if available)\n",
        "    stock_df = fetch_recent_stock_data_polygon(ticker, lookback_days, api_key)\n",
        "    if stock_df is None or stock_df.empty:\n",
        "        print(\"No stock data to assemble features.\")\n",
        "        return None\n",
        "\n",
        "    # 2) Fetch daily sentiment for the same period\n",
        "    sentiment_df = fetch_recent_sentiment_polygon(ticker, lookback_days, api_key)\n",
        "\n",
        "    # 3) Merge\n",
        "    merged_df = pd.merge(stock_df, sentiment_df, on=\"Date\", how=\"left\")\n",
        "    # Forward-fill sentiment if missing\n",
        "    merged_df[[\"sentiment_polarity\", \"sentiment_subjectivity\"]] = (\n",
        "        merged_df[[\"sentiment_polarity\", \"sentiment_subjectivity\"]]\n",
        "        .ffill()\n",
        "        .fillna(0)\n",
        "    )\n",
        "\n",
        "    # Sort by date\n",
        "    merged_df.sort_values(\"Date\", inplace=True)\n",
        "    merged_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    if len(merged_df) < 2:\n",
        "        # We need at least yesterday + today's row\n",
        "        print(\"Not enough data to build a prediction row (need at least 2 days).\")\n",
        "        return None\n",
        "\n",
        "    # The last row is \"today\" (partial), the second-to-last is \"yesterday\"\n",
        "    today_row = merged_df.iloc[-1]\n",
        "    yesterday_row = merged_df.iloc[-2]\n",
        "\n",
        "    # If the last row is truly \"today\" (check if date is today's date):\n",
        "    if today_row[\"Date\"] != datetime.date.today():\n",
        "        print(\"Polygon data doesn’t have today's partial bar yet. No row created.\")\n",
        "        return None\n",
        "\n",
        "    # Build a single-row DataFrame for features\n",
        "    data_dict = {}\n",
        "    # \"prev_\" columns from YESTERDAY\n",
        "    data_dict[\"prev_Open\"] = yesterday_row[\"Open\"]\n",
        "    data_dict[\"prev_High\"] = yesterday_row[\"High\"]\n",
        "    data_dict[\"prev_Low\"]  = yesterday_row[\"Low\"]\n",
        "    data_dict[\"prev_Close\"] = yesterday_row[\"Close\"]\n",
        "    data_dict[\"prev_Volume\"] = yesterday_row[\"Volume\"]\n",
        "\n",
        "    data_dict[\"prev_sentiment_polarity\"] = yesterday_row[\"sentiment_polarity\"]\n",
        "    data_dict[\"prev_sentiment_subjectivity\"] = yesterday_row[\"sentiment_subjectivity\"]\n",
        "\n",
        "    # \"Open_current\" is from TODAY’s row\n",
        "    data_dict[\"Open_current\"] = today_row[\"Open\"]\n",
        "\n",
        "    # Return as a 1-row DataFrame\n",
        "    return pd.DataFrame([data_dict])\n",
        "\n",
        "\n",
        "# Example usage (interactive):\n",
        "if __name__ == \"__main__\":\n",
        "    import getpass\n",
        "\n",
        "    # Example: Polygon Key\n",
        "    polygon_key = getpass.getpass(\"Enter your Polygon.io API key: \")\n",
        "    ticker = \"AAPL\"\n",
        "    one_row_df = assemble_today_prediction_row(ticker, polygon_key)\n",
        "\n",
        "    if one_row_df is not None:\n",
        "        print(\"Single-row DataFrame for prediction:\")\n",
        "        print(one_row_df)\n",
        "    else:\n",
        "        print(\"No row returned.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "hardcoding to make it a trading day"
      ],
      "metadata": {
        "id": "TL_ZFguOnB-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import time\n",
        "from textblob import TextBlob\n",
        "\n",
        "# -------------------------------------\n",
        "# Hard-code today's date as 3/7/2025\n",
        "FAKE_TODAY = datetime.date(2025, 3, 7)\n",
        "# -------------------------------------\n",
        "\n",
        "def fetch_recent_stock_data_polygon(ticker, lookback_days, api_key):\n",
        "    \"\"\"\n",
        "    Fetches ~lookback_days of daily stock data from Polygon.io,\n",
        "    including (possibly partial) data for FAKE_TODAY if we treat it as 'today'.\n",
        "    \"\"\"\n",
        "    # Instead of using datetime.date.today(), use FAKE_TODAY\n",
        "    end_date_dt = FAKE_TODAY\n",
        "    start_date_dt = end_date_dt - datetime.timedelta(days=lookback_days)\n",
        "\n",
        "    start_date = start_date_dt.strftime(\"%Y-%m-%d\")\n",
        "    end_date   = end_date_dt.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    url = (\n",
        "        f\"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/day/\"\n",
        "        f\"{start_date}/{end_date}?apiKey={api_key}\"\n",
        "    )\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error fetching stock data: {response.text}\")\n",
        "        return None\n",
        "\n",
        "    data = response.json()\n",
        "    if \"results\" not in data:\n",
        "        print(\"No results found in Polygon data.\")\n",
        "        return None\n",
        "\n",
        "    df = pd.DataFrame(data[\"results\"])\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"t\"], unit=\"ms\").dt.date\n",
        "    df.rename(columns={\"o\": \"Open\", \"h\": \"High\", \"l\": \"Low\", \"c\": \"Close\", \"v\": \"Volume\"}, inplace=True)\n",
        "    df = df[[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "    df.sort_values(\"Date\", inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def fetch_recent_sentiment_polygon(ticker, lookback_days, api_key, limit=1000):\n",
        "    \"\"\"\n",
        "    Fetches news from Polygon.io for ~lookback_days, computing daily average\n",
        "    sentiment polarity & subjectivity. This includes FAKE_TODAY's partial news if available.\n",
        "    \"\"\"\n",
        "    end_date_dt = FAKE_TODAY\n",
        "    start_date_dt = end_date_dt - datetime.timedelta(days=lookback_days)\n",
        "    start_date = start_date_dt.strftime(\"%Y-%m-%d\")\n",
        "    end_date   = end_date_dt.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    url = \"https://api.polygon.io/v2/reference/news\"\n",
        "    all_results = []\n",
        "    current_start_date = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    final_end_date = datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "\n",
        "    while current_start_date < final_end_date:\n",
        "        chunk_end_date = current_start_date + datetime.timedelta(days=30)\n",
        "        if chunk_end_date > final_end_date:\n",
        "            chunk_end_date = final_end_date\n",
        "\n",
        "        chunk_start_str = current_start_date.strftime(\"%Y-%m-%d\")\n",
        "        chunk_end_str = chunk_end_date.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        params = {\n",
        "            \"ticker\": ticker,\n",
        "            \"published_utc.gte\": chunk_start_str,\n",
        "            \"published_utc.lte\": chunk_end_str,\n",
        "            \"apiKey\": api_key,\n",
        "            \"limit\": limit\n",
        "        }\n",
        "\n",
        "        while True:\n",
        "            response = requests.get(url, params=params)\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                results = data.get(\"results\", [])\n",
        "                all_results.extend(results)\n",
        "\n",
        "                next_cursor = data.get(\"next_cursor\")\n",
        "                if not next_cursor:\n",
        "                    break\n",
        "                params[\"cursor\"] = next_cursor\n",
        "            else:\n",
        "                print(f\"⚠️ Error fetching sentiment data: {response.status_code}, {response.text}\")\n",
        "                break\n",
        "\n",
        "        current_start_date = chunk_end_date\n",
        "        time.sleep(1.5)  # small delay\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    if not all_results:\n",
        "        return pd.DataFrame()\n",
        "    news_df = pd.DataFrame(all_results)\n",
        "\n",
        "    # Compute sentiment using TextBlob\n",
        "    sentiments = []\n",
        "    for _, row in news_df.iterrows():\n",
        "        title = row.get(\"title\", \"\")\n",
        "        description = row.get(\"description\", \"\")\n",
        "        full_text = f\"{title} {description}\"\n",
        "        sentiment = TextBlob(full_text).sentiment\n",
        "        sentiments.append({\n",
        "            \"published_utc\": row.get(\"published_utc\", \"\"),\n",
        "            \"sentiment_polarity\": sentiment.polarity,\n",
        "            \"sentiment_subjectivity\": sentiment.subjectivity\n",
        "        })\n",
        "    sentiment_df = pd.DataFrame(sentiments)\n",
        "\n",
        "    # Group by date\n",
        "    sentiment_df[\"published_date\"] = pd.to_datetime(sentiment_df[\"published_utc\"], errors=\"coerce\").dt.date\n",
        "    daily_sentiment = sentiment_df.groupby(\"published_date\").agg({\n",
        "        \"sentiment_polarity\": \"mean\",\n",
        "        \"sentiment_subjectivity\": \"mean\"\n",
        "    }).reset_index()\n",
        "    daily_sentiment.rename(columns={\"published_date\": \"Date\"}, inplace=True)\n",
        "\n",
        "    return daily_sentiment\n",
        "\n",
        "\n",
        "def assemble_today_prediction_row(ticker, api_key, lookback_days=30):\n",
        "    \"\"\"\n",
        "    Fetches enough data (stock & sentiment) to produce a single row of features\n",
        "    for 'FAKE_TODAY's predicted close.'\n",
        "      - 'prev_' columns are from YESTERDAY's EOD\n",
        "      - 'Open_current' is from FAKE_TODAY's partial bar (the open)\n",
        "\n",
        "    Returns a DataFrame with exactly 1 row:\n",
        "      [prev_Open, prev_High, ..., prev_sentiment_subjectivity, Open_current]\n",
        "    If not enough data is fetched (e.g. no trading yet), returns None.\n",
        "    \"\"\"\n",
        "    # 1) Fetch historical daily data (includes yesterday + partial for FAKE_TODAY if available)\n",
        "    stock_df = fetch_recent_stock_data_polygon(ticker, lookback_days, api_key)\n",
        "    if stock_df is None or stock_df.empty:\n",
        "        print(\"No stock data to assemble features.\")\n",
        "        return None\n",
        "\n",
        "    # 2) Fetch daily sentiment for the same period\n",
        "    sentiment_df = fetch_recent_sentiment_polygon(ticker, lookback_days, api_key)\n",
        "\n",
        "    # 3) Merge\n",
        "    merged_df = pd.merge(stock_df, sentiment_df, on=\"Date\", how=\"left\")\n",
        "    # Forward-fill sentiment if missing\n",
        "    merged_df[[\"sentiment_polarity\", \"sentiment_subjectivity\"]] = (\n",
        "        merged_df[[\"sentiment_polarity\", \"sentiment_subjectivity\"]]\n",
        "        .ffill()\n",
        "        .fillna(0)\n",
        "    )\n",
        "\n",
        "    # Sort by date\n",
        "    merged_df.sort_values(\"Date\", inplace=True)\n",
        "    merged_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    if len(merged_df) < 2:\n",
        "        # We need at least yesterday + 'FAKE_TODAY' row\n",
        "        print(\"Not enough data to build a prediction row (need at least 2 days).\")\n",
        "        return None\n",
        "\n",
        "    # The last row is \"FAKE_TODAY\" (partial), the second-to-last is \"YESTERDAY\"\n",
        "    today_row = merged_df.iloc[-1]\n",
        "    yesterday_row = merged_df.iloc[-2]\n",
        "\n",
        "    # Check if the last row is truly FAKE_TODAY\n",
        "    if today_row[\"Date\"] != FAKE_TODAY:\n",
        "        print(\"Polygon data does not have a row for FAKE_TODAY. No row created.\")\n",
        "        return None\n",
        "\n",
        "    # Build a single-row DataFrame for features\n",
        "    data_dict = {}\n",
        "    # \"prev_\" columns from YESTERDAY\n",
        "    data_dict[\"prev_Open\"] = yesterday_row[\"Open\"]\n",
        "    data_dict[\"prev_High\"] = yesterday_row[\"High\"]\n",
        "    data_dict[\"prev_Low\"]  = yesterday_row[\"Low\"]\n",
        "    data_dict[\"prev_Close\"] = yesterday_row[\"Close\"]\n",
        "    data_dict[\"prev_Volume\"] = yesterday_row[\"Volume\"]\n",
        "\n",
        "    data_dict[\"prev_sentiment_polarity\"] = yesterday_row[\"sentiment_polarity\"]\n",
        "    data_dict[\"prev_sentiment_subjectivity\"] = yesterday_row[\"sentiment_subjectivity\"]\n",
        "\n",
        "    # \"Open_current\" is from FAKE_TODAY's row\n",
        "    data_dict[\"Open_current\"] = today_row[\"Open\"]\n",
        "\n",
        "    return pd.DataFrame([data_dict])\n",
        "\n",
        "\n",
        "# Example usage (interactive):\n",
        "if __name__ == \"__main__\":\n",
        "    import getpass\n",
        "\n",
        "    # Example: Polygon Key (won't actually return real data for 2025, but demo only)\n",
        "    polygon_key = getpass.getpass(\"Enter your Polygon.io API key: \")\n",
        "    ticker = \"AAPL\"\n",
        "    one_row_df = assemble_today_prediction_row(ticker, polygon_key)\n",
        "\n",
        "    if one_row_df is not None:\n",
        "        print(\"Single-row DataFrame for prediction (FAKE 3/7/2025):\")\n",
        "        print(one_row_df)\n",
        "    else:\n",
        "        print(\"No row returned.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "norq8T9UnAYW",
        "outputId": "ec754666-25bf-452e-fe67-188f8261c7ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Polygon.io API key: ··········\n",
            "Single-row DataFrame for prediction (FAKE 3/7/2025):\n",
            "   prev_Open  prev_High  prev_Low  prev_Close  prev_Volume  \\\n",
            "0    234.435     237.86  233.1581      235.33   43505844.0   \n",
            "\n",
            "   prev_sentiment_polarity  prev_sentiment_subjectivity  Open_current  \n",
            "0                -0.102431                     0.439699       235.105  \n"
          ]
        }
      ]
    }
  ]
}